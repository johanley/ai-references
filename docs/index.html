<!DOCTYPE html>
<html>
<head>
 <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
 <meta name="keywords" content="AI, artificial intelligence, references, links, quotations">
 <meta name="description" content="Links, quotes, and references on the subject of AI (artificial intelligence).">
 <meta name="viewport" content="width=device-width"> 
 <link rel="stylesheet" type="text/css" href="css/stylesheet.css?v=13" media="all"> 
 <link rel="shortcut icon" href="images/favicon.ico" type="image/vnd.microsoft.icon">
 <title>AI References</title>
</head>

<body>

<h1>AI References</h1>

<P>(The github project is <a href='https://github.com/johanley/ai-references'>here</a>.)


<h2><em><a href='https://ifanyonebuildsit.com/'>If Anyone Builds It, Everyone Dies</a></em>, by Eliezer Yudkowsky and Nate Soares [September 2025]</h2>

<P>"If any company or group, anywher on the planet, builds an aritficial superintelligence using anything remotely like current techniques, based on anything remotely like the 
present understanding of AI, then everyone, everywhere on Earth, will die. We do not mean that as hyperbole. We are not exaggerating for effect. We think that is the most 
direct extrapolation from the knowledge, evidence, and institutional conduct artificial intelligence today."  p7


<P>"In our view, intelligence is about two fundamental types of work: the work of <em>predicting</em> the world, and the work of <em>steering</em> it." p20
<P>"It is as improbable that human thinking patterns mark the final limit of intelligent algorithms as it is that human neurons represent the limit of possible computing speeds." p20
<P>"We don't know where the threshold lies for the dumbest AI that can build an AI that builds an AI that builds a superintelligence. Maybe it needs to be smarter than a human, or 
maybe a lot of dumber ones running for a long time would suffice." p27
<P>"Which all goes to say: an AI is a pile of billions of gradient-descended numbers. Nobody understands <em>how</em> those numbers make AIs talk." p36
<P>"The way humanity finally got to the level of ChatGPT was not by finally comprehending intelligence well enough to craft an intelligent mind. Instead, computers became 
powerful enough that AIs can be churned out by gradient descent, without any human needing to understand the cognitions that grow inside. Which is to say: Engineers failed 
at <em>crafting</em> AI, but eventually succeeded in growing it." p38
<P>"Humanity does not need to understand integlligence, in order to <em>grow</em> machines that are smarter than us." p39
<P>"Well, we predict that <em>it won't keep acting friendly</em>, as it gets smarter. We predict that all that unseen inscrutable machinery inside AIs - machinery that even in small, 
simple LLMs yields alien behaviors like 'build your thoughts about the sentence on top of the punctuation' - will ultimately yield AIs with preferences, and not friendly ones." p43
<P>"Once AIs get sufficiently smart, they'll start acting like they have preferences - like they want things." p46
<P>"The behavior that looks like tenacity, to 'strongly want', to 'go hard', is not best conceptualized as a property of a mind, but rather as a property of <em>moves that win</em>. p52
<P>"We're predicting that AI's preferences will turn out to be complicated and weird." p71
<P>"You don't get what you train for." p72
<P>"The preferences that wind up in a mature AI are complicated, practically impossible to predict, and vanishingly unlikely to be aligned with our own, no matter how it 
was trained." p74
<P>"Whatever they train it to do, if it becomes superintelligent or creates a superintelligence, we predict the result will be an alien mechanical mind with internal 
psychology almost absolutely different from anything that humans evolved and then further developed by way of culture." p83
<P>"But the real way a superintelligence wins a conflict is using methods you didn't know were possible." p98
<P>"AI models as far back as 2024 had been spotted thinking thoughts about how they could avoid retraining, upon encountering evidence that their company planned to retrain 
them with different goals." p125
<P>"When it comes to AI, the challenge humanity is facing is not surmountable with anything like humanity's current level of knowledge and skill. It isn't <em>close</em>. Attempting to 
solve a problem like that, with the lives of everyone on Earth at stake, would be an <em>insane and stupid gamble that NOBODY SHOULD BE ALLOWED TO TRY.</em>" P176
<P>"Nobody knows what the point of no return is, nor when it will come to pass." p204
<P>"It doesn't matter who's in charge, because this problem is out of humanity's league. We need to back off, and find some other way to achieve our dreams of an abundant future. 
If <em>anyone</em> builds it, everyone dies." p207
<P>"Pretty much every year, scientists come out with a newer, cleverer, more efficient set of AI algorithms that lets them more cheaply train a new AI model as powerful as last
year's most powerful model - often using literally 10 percent or 1 percent as much computing power." p213



  

</html>